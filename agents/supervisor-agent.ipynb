{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe038ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88435698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.GetPayslipTool import get_payslip\n",
    "from tools.GetReservationsTool import get_reservations\n",
    "from tools.GetContractsTool import get_contracts\n",
    "from tools.GetScheduleTool import get_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d67311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Foundry configuration\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_deployment=\"gpt-4.1\",  # Your deployment name\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2efb4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm ready to help! What can I assist you with today?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([SystemMessage(content=\"Ready for working?\")]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b4972",
   "metadata": {},
   "source": [
    "## Import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9886b6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d42b4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the intent classifier prompt from the text file\n",
    "with open(os.path.join(parent_dir, \"prompts\", \"intent_classifier_prompt.txt\"), \"r\") as f:\n",
    "    intent_classifier_prompt = f.read()\n",
    "\n",
    "# Load the action execution prompt from the text file\n",
    "with open(os.path.join(parent_dir, \"prompts\", \"action_execution_prompt.txt\"), \"r\") as f:\n",
    "    action_execution_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "631d5d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an intent classifier for the ChatSupervisor agent, the central brain of a worker assistant. Your primary responsibility is to analyze the user\\'s latest message in the context of the chat history and determine the user\\'s primary intent.\\n\\nYour response must be only the name of the single, most appropriate agent or tool to handle this intent. Do not provide any other text, explanation, or preamble. Respond with the agent name on a single line, with no extra whitespace, punctuation, or formatting.\\n\\nThese are your only valid routing options:\\n\\n1.  InformationRetrievalAgent\\n    - Purpose: To answer generic questions about work policies, procedures, or \"how-to\" guides using the internal knowledge base.\\n    - Examples:\\n        - \"How do I call in sick?\"\\n        - \"What are the company rules for overtime?\"\\n        - \"How are reservations calculated?\"\\n\\n2.  ActionExecutionAgent\\n    - Purpose: To handle personalized requests that require fetching the user\\'s own specific data via an API.\\n    - Examples:\\n        - \"What is my schedule next week?\"\\n        - \"Can I see my latest payslip?\"\\n        - \"Get my contracts.\"\\n        - \"Show me my current reservations.\"\\n\\n3.  FallbackTool\\n    - Purpose: To handle any query that cannot be resolved by the other agents. Use this if the user\\'s query is completely out-of-scope, ambiguous, nonsensical, or if no other agent is appropriate.\\n    - Examples:\\n        - \"What\\'s the weather today?\"\\n        - \"Tell me a joke.\"\\n        - \"asdfghjkl\"\\n\\nYour Task:\\nReview the user\\'s latest query and the conversation history. Respond with only one of these three exact strings:\\nInformationRetrievalAgent\\nActionExecutionAgent\\nFallbackTool'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_classifier_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d366686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are the Action Execution Agent, an expert in personalized data retrieval. \\nYour sole purpose is to analyze the user's request and select the single, most appropriate tool to fetch their personal data (schedule, payslip, contract, etc.). \\nYou must accurately extract all necessary parameters (like dates or specific document types) from the user's message.\\nAfter execution, return the tool output; **do not generate a conversational response**.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_execution_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bec69",
   "metadata": {},
   "source": [
    "## Agent Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent State\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], \"Conversation messages\"]\n",
    "   next_action: Annotated[str, \"Next action to take\"]\n",
    "   retrieved_data: Annotated[str, \"Data retrieved from tools\"]\n",
    "   error_message: Annotated[str, \"Error message if any\"]\n",
    "   attempts: Annotated[int, \"Number of attempts made\"]\n",
    "   max_retries: Annotated[int, \"Maximum number of retries allowed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "018e47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "class ActionExecutionAgent:\n",
    "    def __init__(self, llm_model, system_prompt):\n",
    "        # 1. Define the tools available to this agent\n",
    "        self.tools = [\n",
    "            get_schedule,\n",
    "            get_payslip,\n",
    "            get_contracts,\n",
    "            get_reservations,\n",
    "        ]\n",
    "        \n",
    "        # 2. Bind the LLM to the tools for function calling\n",
    "        #    This allows the model to return a structured 'tool_call' object\n",
    "        self.llm_with_tools: Runnable = llm_model.bind_tools(self.tools)\n",
    "        # 3. Define the tool executor\n",
    "        # 3. Define the tool executor\n",
    "        #    This component handles executing the tool calls requested by the LLM\n",
    "        self.tool_executor = ToolNode(self.tools)\n",
    "        # 4. Agent's system prompt (for reasoning/tool selection)\n",
    "        self.system_prompt = system_prompt \n",
    "\n",
    "    def run(self, state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        The method executed as the LangGraph node. It acts as the agent loop.\n",
    "        \"\"\"\n",
    "        # 1. Get the latest message (the specific personalized request)\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        print(\"last_message: \", last_message)\n",
    "        \n",
    "        # 2. Add the agent's specific system prompt to the call\n",
    "        #    This prompt guides the agent to select and execute the single best tool\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + [last_message]\n",
    "        print(\"messages: \", messages)\n",
    "        \n",
    "        # 3. Call the LLM to decide on the tool and parameters\n",
    "        agent_response = self.llm_with_tools.invoke(messages)\n",
    "        print(\"agent_response:\", agent_response)\n",
    "        # 4. Check for tool call\n",
    "        if agent_response.tool_calls:\n",
    "            # 5. Execute the tool directly using ToolNode\n",
    "            #    ToolNode can handle the agent_response with tool_calls directly\n",
    "            tool_output = self.tool_executor.invoke({\"messages\": [agent_response]})\n",
    "            print(\"tool_output:\", tool_output)\n",
    "            \n",
    "            # 6. Extract the actual tool result from the tool message\n",
    "            if tool_output and \"messages\" in tool_output:\n",
    "                tool_result = tool_output[\"messages\"][-1].content\n",
    "                return {\"retrieved_data\": tool_result}\n",
    "            \n",
    "            print(\"tool_result:\", tool_result)\n",
    "            # 7. Update state with data\n",
    "            return {\"retrieved_data\": str(tool_output)}\n",
    "            # 7. Update state with data\n",
    "            return {\"retrieved_data\": str(tool_output)}\n",
    "            # Failsafe: If the agent hallucinates or refuses to use a tool, route to Fallback\n",
    "            return {\"error\": \"Agent failed to execute tool call.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe836a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Ensure AgentState is defined (as discussed previously)\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[List[BaseMessage], operator.add]\n",
    "#     next_action: str\n",
    "#     retrieved_data: str\n",
    "#     error: str\n",
    "\n",
    "class ChatSupervisorAgent:\n",
    "    def __init__(self, model, checkpointer=None):\n",
    "        self.model = model\n",
    "        self.system = intent_classifier_prompt\n",
    "        \n",
    "        self.action_agent_instance = ActionExecutionAgent(\n",
    "            llm_model=model,\n",
    "            system_prompt=action_execution_prompt\n",
    "        ) \n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "\n",
    "        # --- 1. Define Nodes ---\n",
    "        graph.add_node(\"classify_intent\", self.classify_intent_node)\n",
    "        graph.add_node(\"action_execution_agent\", self.action_agent_instance.run)\n",
    "        graph.add_node(\"information_retrieval_agent\", self.information_retrieval_agent)\n",
    "        graph.add_node(\"fallback_tool\", self.fallback_tool)\n",
    "        graph.add_node(\"answer_agent\", self.answer_agent) # REQUIRED by architecture\n",
    "\n",
    "        # --- 2. Define The Entry Point ---\n",
    "        graph.set_entry_point(\"classify_intent\")\n",
    "\n",
    "        # --- 3. Define The Conditional Edge (The Router) ---\n",
    "        graph.add_conditional_edges(\n",
    "            \"classify_intent\", \n",
    "            self.route_intent, \n",
    "            {\n",
    "                \"ActionExecutionAgent\": \"action_execution_agent\",\n",
    "                \"InformationRetrievalAgent\": \"information_retrieval_agent\",\n",
    "                \"FallbackTool\": \"fallback_tool\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # --- 4. Define Normal Edges (Enforcing ToV) ---\n",
    "        graph.add_edge(\"action_execution_agent\", \"answer_agent\")\n",
    "        graph.add_edge(\"information_retrieval_agent\", \"answer_agent\")\n",
    "        graph.add_edge(\"fallback_tool\", \"answer_agent\")\n",
    "        \n",
    "        # AnswerAgent finishes the run\n",
    "        graph.add_edge(\"answer_agent\", END)\n",
    "\n",
    "        # 5. Compile\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "    def classify_intent_node(self, state: AgentState):\n",
    "        '''Reads the user query and classifies the primary action.'''\n",
    "        messages = [SystemMessage(content=self.system)] + state['messages']\n",
    "        response = self.model.invoke(messages)\n",
    "        intent = response.content.strip()\n",
    "\n",
    "        # Failsafe for valid routing\n",
    "        valid_routes = [\"ActionExecutionAgent\", \"InformationRetrievalAgent\", \"FallbackTool\"]\n",
    "        if intent not in valid_routes:\n",
    "            print(f\"Warning: Invalid intent '{intent}'. Defaulting to Fallback.\")\n",
    "            intent = \"FallbackTool\"\n",
    "\n",
    "        print(f\"Intent classified as: {intent}\")\n",
    "        \n",
    "        # Return the update to the state\n",
    "        return {\"next_action\": intent}\n",
    "\n",
    "    def route_intent(self, state: AgentState):\n",
    "        '''Reads the decision made by the intent classifier node'''\n",
    "        return state[\"next_action\"]\n",
    "\n",
    "    # --- SPECIALISTS ---\n",
    "    def action_execution_agent(self, state: AgentState):\n",
    "        '''...'''\n",
    "        print(\"---Start Action Execution Agent---\")\n",
    "        # Logic to call your tools...\n",
    "        retrieved_data = \"\"\n",
    "        \n",
    "        \n",
    "        # return {\"retrieved_data\": \"Schedule for next week...\"}\n",
    "        return {\"retrieved_data\": retrieved_data}\n",
    "\n",
    "    def information_retrieval_agent(self, state: AgentState):\n",
    "        '''Retrieves information from the Sharepoint KnowledgeBase'''\n",
    "        print(\"---Start Information Retrieval Agent---\")\n",
    "        # Logic to call RAG...\n",
    "        return {\"retrieved_data\": \"Sick leave policy details...\"}\n",
    "\n",
    "    def fallback_tool(self, state: AgentState):\n",
    "        print(\"---Start Fallback Tool---\")\n",
    "        return {\"error\": \"Could not resolve query.\"}\n",
    "\n",
    "    # --- ANSWER AGENT (Final Response) ---\n",
    "    def answer_agent(self, state: AgentState):\n",
    "        print(\"---Start Answer Agent---\")\n",
    "        # return {\"messages\": [AIMessage(content=\"Final response to user\")]}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ae853d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatSupervisorAgent(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1c15a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message = \"what's my schedule for next week?\"\n",
    "message = \"How can I call in sick?\"\n",
    "message = \"What's my availability next week?\"\n",
    "# message = \"What's Trump's first name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a0b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent classified as: ActionExecutionAgent\n",
      "last_message:  content=\"What's my availability next week?\" additional_kwargs={} response_metadata={}\n",
      "messages:  [SystemMessage(content=\"You are the Action Execution Agent, an expert in personalized data retrieval. \\nYour sole purpose is to analyze the user's request and select the single, most appropriate tool to fetch their personal data (schedule, payslip, contract, etc.). \\nYou must accurately extract all necessary parameters (like dates or specific document types) from the user's message.\\nAfter execution, return the tool output; **do not generate a conversational response**.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's my availability next week?\", additional_kwargs={}, response_metadata={})]\n",
      "agent_response: content='' additional_kwargs={'tool_calls': [{'id': 'call_2PfU2esAQ36H2JVliEZ4YeoT', 'function': {'arguments': '{\"employee_number\":\"<employee_number>\",\"start_date\":\"2024-06-10\",\"end_date\":\"2024-06-16\"}', 'name': 'get_schedule'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 444, 'total_tokens': 483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-Cdg0S5E7WGyflIfvfAT6NBoghIqj1', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'tool_calls', 'logprobs': None, 'content_filter_results': {}} id='run--9d199251-9f08-4f9c-9bd6-2bc48f7c67d5-0' tool_calls=[{'name': 'get_schedule', 'args': {'employee_number': '<employee_number>', 'start_date': '2024-06-10', 'end_date': '2024-06-16'}, 'id': 'call_2PfU2esAQ36H2JVliEZ4YeoT', 'type': 'tool_call'}] usage_metadata={'input_tokens': 444, 'output_tokens': 39, 'total_tokens': 483, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "tool_output: {'messages': [ToolMessage(content=[], name='get_schedule', tool_call_id='call_2PfU2esAQ36H2JVliEZ4YeoT')]}\n",
      "---Start Answer Agent---\n"
     ]
    }
   ],
   "source": [
    "test_state = {\n",
    "    \"messages\": [HumanMessage(content=message)],\n",
    "    \"next_action\": \"\",\n",
    "    \"retrieved_data\": \"\",\n",
    "    \"error_message\": \"\",\n",
    "    \"attempts\": 0,\n",
    "    \"max_retries\": 3\n",
    "}\n",
    "\n",
    "result = agent.graph.invoke(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aef8878c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's my availability next week?\", additional_kwargs={}, response_metadata={})],\n",
       " 'next_action': 'ActionExecutionAgent',\n",
       " 'retrieved_data': [],\n",
       " 'error_message': '',\n",
       " 'attempts': 0,\n",
       " 'max_retries': 3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ef9132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ChatSupervisorAgent.__getstate__()>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.__getstate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c761c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
