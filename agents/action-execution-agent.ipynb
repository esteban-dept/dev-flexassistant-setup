{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564a84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.runnables import Runnable\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9042aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.agent_state import AgentState\n",
    "\n",
    "from tools.GetPayslipTool import get_payslip\n",
    "from tools.GetReservationsTool import get_reservations\n",
    "from tools.GetContractsTool import get_contracts\n",
    "from tools.GetScheduleTool import get_schedule\n",
    "\n",
    "# Load the action execution prompt from the text file\n",
    "with open(os.path.join(parent_dir, \"prompts\", \"action_execution_prompt.txt\"), \"r\") as f:\n",
    "    action_execution_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bbe35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.llm_model import AzureModelProvider\n",
    "provider = AzureModelProvider()\n",
    "llm = provider.get_primary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9cd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionExecutionAgent:\n",
    "    def __init__(self, llm_model, system_prompt):\n",
    "        # 1. Define the tools available to this agent\n",
    "        self.tools = [\n",
    "            get_schedule,\n",
    "            get_payslip,\n",
    "            get_contracts,\n",
    "            get_reservations,\n",
    "        ]\n",
    "        \n",
    "        # 2. Bind the LLM to the tools for function calling\n",
    "        #    This allows the model to return a structured 'tool_call' object\n",
    "        self.llm_with_tools: Runnable = llm_model.bind_tools(self.tools)\n",
    "        # 3. Define the tool executor\n",
    "        # 3. Define the tool executor\n",
    "        #    This component handles executing the tool calls requested by the LLM\n",
    "        self.tool_executor = ToolNode(self.tools)\n",
    "        # 4. Agent's system prompt (for reasoning/tool selection)\n",
    "        self.system_prompt = system_prompt \n",
    "\n",
    "    def run(self, state: AgentState) -> dict:\n",
    "        \"\"\"\n",
    "        The method executed as the LangGraph node. It acts as the agent loop.\n",
    "        \"\"\"\n",
    "        # 1. Get the latest message (the specific personalized request)\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        print(\"last_message: \", last_message)\n",
    "        \n",
    "        # 2. Add the agent's specific system prompt to the call\n",
    "        #    This prompt guides the agent to select and execute the single best tool\n",
    "        messages = [SystemMessage(content=self.system_prompt)] + [last_message]\n",
    "        print(\"messages: \", messages)\n",
    "        \n",
    "        # 3. Call the LLM to decide on the tool and parameters\n",
    "        agent_response = self.llm_with_tools.invoke(messages)\n",
    "        print(\"agent_response:\", agent_response)\n",
    "        # 4. Check for tool call\n",
    "        if agent_response.tool_calls:\n",
    "            # 5. Execute the tool directly using ToolNode\n",
    "            #    ToolNode can handle the agent_response with tool_calls directly\n",
    "            tool_output = self.tool_executor.invoke({\"messages\": [agent_response]})\n",
    "            print(\"tool_output:\", tool_output)\n",
    "            \n",
    "            # 6. Extract the actual tool result from the tool message\n",
    "            if tool_output and \"messages\" in tool_output:\n",
    "                tool_result = tool_output[\"messages\"][-1].content\n",
    "                return {\"retrieved_data\": tool_result}\n",
    "            \n",
    "            print(\"tool_result:\", tool_result)\n",
    "            # 7. Update state with data\n",
    "            return {\"retrieved_data\": str(tool_output)}\n",
    "            # 7. Update state with data\n",
    "            return {\"retrieved_data\": str(tool_output)}\n",
    "            # Failsafe: If the agent hallucinates or refuses to use a tool, route to Fallback\n",
    "            return {\"error\": \"Agent failed to execute tool call.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6042214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_agent_instance = ActionExecutionAgent(\n",
    "            llm_model=llm,\n",
    "            system_prompt=action_execution_prompt\n",
    "        ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
