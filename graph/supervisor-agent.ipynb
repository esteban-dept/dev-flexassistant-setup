{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe038ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d67311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Foundry configuration\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_deployment=\"gpt-4.1\",  # Your deployment name\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2efb4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm ready to help! What do you need assistance with today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([SystemMessage(content=\"Ready for working?\")]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b4972",
   "metadata": {},
   "source": [
    "## Import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42b4781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an intent classifier for the ChatSupervisor agent, the central brain of a worker assistant. Your primary responsibility is to analyze the user\\'s latest message in the context of the chat history and determine the user\\'s primary intent.\\n\\nYour response must be only the name of the single, most appropriate agent or tool to handle this intent. Do not provide any other text, explanation, or preamble. Respond with the agent name on a single line, with no extra whitespace, punctuation, or formatting.\\n\\nThese are your only valid routing options:\\n\\n1.  InformationRetrievalAgent\\n    - Purpose: To answer generic questions about work policies, procedures, or \"how-to\" guides using the internal knowledge base.\\n    - Examples:\\n        - \"How do I call in sick?\"\\n        - \"What are the company rules for overtime?\"\\n        - \"How are reservations calculated?\"\\n\\n2.  ActionExecutionAgent\\n    - Purpose: To handle personalized requests that require fetching the user\\'s own specific data via an API.\\n    - Examples:\\n        - \"What is my schedule next week?\"\\n        - \"Can I see my latest payslip?\"\\n        - \"Get my contracts.\"\\n        - \"Show me my current reservations.\"\\n\\n3.  FallbackTool\\n    - Purpose: To handle any query that cannot be resolved by the other agents. Use this if the user\\'s query is completely out-of-scope, ambiguous, nonsensical, or if no other agent is appropriate.\\n    - Examples:\\n        - \"What\\'s the weather today?\"\\n        - \"Tell me a joke.\"\\n        - \"asdfghjkl\"\\n\\nYour Task:\\nReview the user\\'s latest query and the conversation history. Respond with only one of these three exact strings:\\nInformationRetrievalAgent\\nActionExecutionAgent\\nFallbackTool'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Load the intent classifier prompt from the text file\n",
    "with open(os.path.join(parent_dir, \"prompts\", \"intent_classifier.txt\"), \"r\") as f:\n",
    "    intent_classifier_prompt = f.read()\n",
    "\n",
    "intent_classifier_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bec69",
   "metadata": {},
   "source": [
    "## Agent Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc9e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent State\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], \"Conversation messages\"]\n",
    "   next_action: Annotated[str, \"Next action to take\"]\n",
    "   retrieved_data: Annotated[str, \"Data retrieved from tools\"]\n",
    "   error_message: Annotated[str, \"Error message if any\"]\n",
    "   attempts: Annotated[int, \"Number of attempts made\"]\n",
    "   max_retries: Annotated[int, \"Maximum number of retries allowed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe836a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Ensure AgentState is defined (as discussed previously)\n",
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[List[BaseMessage], operator.add]\n",
    "#     next_action: str\n",
    "#     retrieved_data: str\n",
    "#     error: str\n",
    "\n",
    "class ChatSupervisorAgent:\n",
    "    def __init__(self, model, checkpointer=None):\n",
    "        self.model = model\n",
    "        self.system = intent_classifier_prompt \n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "\n",
    "        # --- 1. Define Nodes ---\n",
    "        graph.add_node(\"classify_intent\", self.classify_intent_node)\n",
    "        graph.add_node(\"action_execution_agent\", self.action_execution_agent)\n",
    "        graph.add_node(\"information_retrieval_agent\", self.information_retrieval_agent)\n",
    "        graph.add_node(\"fallback_tool\", self.fallback_tool)\n",
    "        graph.add_node(\"answer_agent\", self.answer_agent) # REQUIRED by architecture\n",
    "\n",
    "        # --- 2. Define The Entry Point ---\n",
    "        graph.set_entry_point(\"classify_intent\")\n",
    "\n",
    "        # --- 3. Define The Conditional Edge (The Router) ---\n",
    "        graph.add_conditional_edges(\n",
    "            \"classify_intent\", \n",
    "            self.route_intent, \n",
    "            {\n",
    "                \"ActionExecutionAgent\": \"action_execution_agent\",\n",
    "                \"InformationRetrievalAgent\": \"information_retrieval_agent\",\n",
    "                \"FallbackTool\": \"fallback_tool\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # --- 4. Define Normal Edges (Enforcing ToV) ---\n",
    "        graph.add_edge(\"action_execution_agent\", \"answer_agent\")\n",
    "        graph.add_edge(\"information_retrieval_agent\", \"answer_agent\")\n",
    "        graph.add_edge(\"fallback_tool\", \"answer_agent\")\n",
    "        \n",
    "        # AnswerAgent finishes the run\n",
    "        graph.add_edge(\"answer_agent\", END)\n",
    "\n",
    "        # 5. Compile\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "    def classify_intent_node(self, state: AgentState):\n",
    "        '''Reads the user query and classifies the primary action.'''\n",
    "        messages = [SystemMessage(content=self.system)] + state['messages']\n",
    "        response = self.model.invoke(messages)\n",
    "        intent = response.content.strip()\n",
    "\n",
    "        # Failsafe for valid routing\n",
    "        valid_routes = [\"ActionExecutionAgent\", \"InformationRetrievalAgent\", \"FallbackTool\"]\n",
    "        if intent not in valid_routes:\n",
    "            print(f\"Warning: Invalid intent '{intent}'. Defaulting to Fallback.\")\n",
    "            intent = \"FallbackTool\"\n",
    "\n",
    "        print(f\"Intent classified as: {intent}\")\n",
    "        \n",
    "        # Return the update to the state\n",
    "        return {\"next_action\": intent}\n",
    "\n",
    "    def route_intent(self, state: AgentState):\n",
    "        '''Reads the decision made by the intent classifier node'''\n",
    "        return state[\"next_action\"]\n",
    "\n",
    "    # --- SPECIALISTS ---\n",
    "    def action_execution_agent(self, state: AgentState):\n",
    "        '''...'''\n",
    "        print(\"---Start Action Execution Agent---\")\n",
    "        # Logic to call your tools...\n",
    "        # return {\"retrieved_data\": \"Schedule for next week...\"}\n",
    "        return {\"retrieved_data\": \"Success placeholder\"}\n",
    "\n",
    "    def information_retrieval_agent(self, state: AgentState):\n",
    "        '''Retrieves information from the Sharepoint KnowledgeBase'''\n",
    "        print(\"---Start Information Retrieval Agent---\")\n",
    "        # Logic to call RAG...\n",
    "        return {\"retrieved_data\": \"Sick leave policy details...\"}\n",
    "\n",
    "    def fallback_tool(self, state: AgentState):\n",
    "        print(\"---Start Fallback Tool---\")\n",
    "        return {\"error\": \"Could not resolve query.\"}\n",
    "\n",
    "    # --- ANSWER AGENT (Final Response) ---\n",
    "    def answer_agent(self, state: AgentState):\n",
    "        print(\"---Start Answer Agent---\")\n",
    "        # return {\"messages\": [AIMessage(content=\"Final response to user\")]}\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ae853d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatSupervisorAgent(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1c15a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# message = \"what's my schedule for next week?\"\n",
    "message = \"How can I call in sick?\"\n",
    "# message = \"What's my availability next week?\"\n",
    "# message = \"What's Trump's first name?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0a0b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent classified as: InformationRetrievalAgent\n",
      "---Start Information Retrieval Agent---\n",
      "---Start Answer Agent---\n"
     ]
    }
   ],
   "source": [
    "test_state = {\n",
    "    \"messages\": [HumanMessage(content=message)],\n",
    "    \"next_action\": \"\",\n",
    "    \"retrieved_data\": \"\",\n",
    "    \"error_message\": \"\",\n",
    "    \"attempts\": 0,\n",
    "    \"max_retries\": 3\n",
    "}\n",
    "\n",
    "result = agent.graph.invoke(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aef8878c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How can I call in sick?', additional_kwargs={}, response_metadata={})],\n",
       " 'next_action': 'InformationRetrievalAgent',\n",
       " 'retrieved_data': 'Sick leave policy details...',\n",
       " 'error_message': '',\n",
       " 'attempts': 0,\n",
       " 'max_retries': 3}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f290b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e95e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
