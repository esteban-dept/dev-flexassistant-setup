{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe038ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d67311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI Foundry configuration\n",
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    azure_deployment=\"gpt-4.1\",  # Your deployment name\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2efb4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm ready to help! What do you need assistance with today?\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([SystemMessage(content=\"Ready for working?\")]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6b4972",
   "metadata": {},
   "source": [
    "## Import Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d42b4781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an intent classifier for the ChatSupervisor agent, the central brain of a worker assistant. Your primary responsibility is to analyze the user\\'s latest message in the context of the chat history and determine the user\\'s primary intent.\\n\\nYour response must be only the name of the single, most appropriate agent or tool to handle this intent. Do not provide any other text, explanation, or preamble. Respond with the agent name on a single line, with no extra whitespace, punctuation, or formatting.\\n\\nThese are your only valid routing options:\\n\\n1.  InformationRetrievalAgent\\n    - Purpose: To answer generic questions about work policies, procedures, or \"how-to\" guides using the internal knowledge base.\\n    - Examples:\\n        - \"How do I call in sick?\"\\n        - \"What are the company rules for overtime?\"\\n        - \"How are reservations calculated?\"\\n\\n2.  ActionExecutionAgent\\n    - Purpose: To handle personalized requests that require fetching the user\\'s own specific data via an API.\\n    - Examples:\\n        - \"What is my schedule next week?\"\\n        - \"Can I see my latest payslip?\"\\n        - \"Get my contracts.\"\\n        - \"Show me my current reservations.\"\\n\\n3.  FallbackTool\\n    - Purpose: To handle any query that cannot be resolved by the other agents. Use this if the user\\'s query is completely out-of-scope, ambiguous, nonsensical, or if no other agent is appropriate.\\n    - Examples:\\n        - \"What\\'s the weather today?\"\\n        - \"Tell me a joke.\"\\n        - \"asdfghjkl\"\\n\\nYour Task:\\nReview the user\\'s latest query and the conversation history. Respond with only one of these three exact strings:\\nInformationRetrievalAgent\\nActionExecutionAgent\\nFallbackTool'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Load the intent classifier prompt from the text file\n",
    "with open(os.path.join(parent_dir, \"prompts\", \"intent_classifier.txt\"), \"r\") as f:\n",
    "    intent_classifier_prompt = f.read()\n",
    "\n",
    "intent_classifier_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bec69",
   "metadata": {},
   "source": [
    "## Agent Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc9e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent State\n",
    "class AgentState(TypedDict):\n",
    "   messages: Annotated[list[AnyMessage], \"Conversation messages\"]\n",
    "   next_action: Annotated[str, \"Next action to take\"]\n",
    "   retrieved_data: Annotated[str, \"Data retrieved from tools\"]\n",
    "   error_message: Annotated[str, \"Error message if any\"]\n",
    "   attempts: Annotated[int, \"Number of attempts made\"]\n",
    "   max_retries: Annotated[int, \"Maximum number of retries allowed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe836a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "class ChatSupervisorAgent:\n",
    "    def __init__(self, model, checkpointer=None):\n",
    "        self.model = model\n",
    "        # The system prompt is the intent classifier\n",
    "        self.system = intent_classifier_prompt\n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "\n",
    "        # 1. Define the node that classifies intent\n",
    "        graph.add_node(\"classify_intent\", self.classify_intent_node)\n",
    "\n",
    "        # 2. Define the conditional edge (the router)\n",
    "        graph.add_conditional_edges(\n",
    "            \"classify_intent\",  # Start from the classifier node\n",
    "            self.route_intent,   # Use this function to find the next step\n",
    "            {\n",
    "                # Keys must match the strings from the prompt\n",
    "                \"ActionExecutionAgent\": \"action_execution_agent\",\n",
    "                \"InformationRetrievalAgent\": \"information_retrieval_agent\",\n",
    "                \"FallbackTool\": \"fallback_tool\",\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 3. Set the entry point for the graph\n",
    "        graph.set_entry_point(\"classify_intent\")\n",
    "\n",
    "        # --- Define Specialist Nodes ---\n",
    "        # graph.add_node(\"action_execution_agent\", action_agent_runnable)\n",
    "        # graph.add_node(\"information_retrieval_agent\", retrieval_agent_runnable)\n",
    "        # graph.add_node(\"fallback_tool\", fallback_runnable)\n",
    "        # graph.add_node(\"answer_agent\", answer_agent_runnable)\n",
    "\n",
    "        # --- Define Edges to AnswerAgent (Enforcing ToV) ---\n",
    "        # As per the brief, all specialists must go to the AnswerAgent\n",
    "        # graph.add_edge(\"action_execution_agent\", \"answer_agent\")\n",
    "        # graph.add_edge(\"information_retrieval_agent\", \"answer_agent\")\n",
    "        # graph.add_edge(\"fallback_tool\", \"answer_agent\")\n",
    "        # graph.add_edge(\"answer_agent\", END) # End the graph run\n",
    "\n",
    "        # 4. Compile the graph\n",
    "        # self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        # print(\"Graph structure defined.\")\n",
    "    \n",
    "    def classify_intent_node(self, state: AgentState):\n",
    "        \"\"\"\n",
    "        Calls the LLM with the intent classifier prompt to decide the next step.\n",
    "        Updates the 'next_node' field in the state.\n",
    "        \"\"\"\n",
    "        print(\"---SUPERVISOR: CLASSIFYING INTENT---\")\n",
    "        \n",
    "        # Prepare the prompt and messages\n",
    "        messages = [HumanMessage(content=self.system)]\n",
    "        messages.extend(state['messages'])\n",
    "\n",
    "        # Call the model\n",
    "        response = self.model.invoke(messages)\n",
    "        intent = response.content.strip()\n",
    "\n",
    "        # Failsafe: If LLM returns an invalid route, force fallback\n",
    "        if intent not in [\"ActionExecutionAgent\", \"InformationRetrievalAgent\", \"FallbackTool\"]:\n",
    "            print(f\"Warning: LLM returned invalid intent '{intent}'. Forcing Fallback.\")\n",
    "            intent = \"FallbackTool\"\n",
    "\n",
    "        print(f\"Intent classified as: {intent}\")\n",
    "        \n",
    "        # Update the state so the router can read it\n",
    "        return {\"next_node\": intent}\n",
    "    \n",
    "    def route_intent(self, state: AgentState) -> str:\n",
    "        \"\"\"\n",
    "        Reads the 'next_node' field from the state and returns it.\n",
    "        This tells LangGraph which node to go to next.\n",
    "        \"\"\"\n",
    "        intent = state.get(\"next_node\")\n",
    "        print(f\"---SUPERVISOR: ROUTING TO: {intent}---\")\n",
    "        \n",
    "        if not intent:\n",
    "            return \"FallbackTool\" # Should not happen, but good failsafe\n",
    "            \n",
    "        return intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ae853d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatSupervisorAgent(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1c15a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SUPERVISOR: CLASSIFYING INTENT---\n",
      "Intent classified as: ActionExecutionAgent\n",
      "Intent classified as: ActionExecutionAgent\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a sample message\n",
    "test_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What is my payroll?\")],\n",
    "    \"next_action\": \"\",\n",
    "    \"retrieved_data\": \"\",\n",
    "    \"error_message\": \"\",\n",
    "    \"attempts\": 0,\n",
    "    \"max_retries\": 3\n",
    "}\n",
    "\n",
    "result = agent.classify_intent_node(test_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e95e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
